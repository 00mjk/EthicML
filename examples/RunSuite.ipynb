{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EthicML\n",
    "\n",
    "## Runnning experiments on the Adult dataset\n",
    "\n",
    "### Installation\n",
    "\n",
    "First we need to install EthicML. Currently, the toolkit isn't on PyPi, but this will change soon.\n",
    "\n",
    "For now, the toolkit has to be cloned, then installed as an editable package\n",
    "```\n",
    "cd <Location to clone to>\n",
    "git clone https://github.com/predictive-analytics-lab/EthicML.git\n",
    "cd EthicML\n",
    "pip install --editable ./\n",
    "```\n",
    "\n",
    "(Obviously this notebook is within the package, so we can skip this step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "EthicML includes some often used datasets from fairness literature.\n",
    "First, we load one of these... in this example we load the UCI Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ethicml.utility import DataTuple\n",
    "from ethicml.data.load import load_data\n",
    "from ethicml.data import Adult, Compas, Credit, German, Sqf, Toy\n",
    "\n",
    "data: DataTuple = load_data(Adult())\n",
    "assert (45222, 101) == data.x.shape\n",
    "assert (45222, 1) == data.s.shape\n",
    "assert (45222, 1) == data.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the dataset as a DataTuple, which comprises $x$ (features), $s$ (sensitive attribute and $y$ (class label). Each member of the DataTuple is stored as a Pandas DataFrame.\n",
    "\n",
    "By default, the Adult dataset uses the binary attribute `sex_Male` as the sensitive feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_Male\n",
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to run experiments using race as the sensitive attribute we could change that manually, or, as this is a common task, EthicML can split the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: DataTuple = load_data(Adult(split=\"Race\"))\n",
    "assert (45222, 98) == data.x.shape\n",
    "assert (45222, 5) == data.s.shape\n",
    "assert (45222, 1) == data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_Amer-Indian-Eskimo</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_Amer-Indian-Eskimo  race_Asian-Pac-Islander  race_Black  race_Other  \\\n",
       "0                        0                        0           0           0   \n",
       "1                        0                        0           0           0   \n",
       "2                        0                        0           0           0   \n",
       "3                        0                        0           1           0   \n",
       "4                        0                        0           0           0   \n",
       "\n",
       "   race_White  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we're going to be repeating some of the experiments from FairGP. In that paper they do experiments with race as the sensitive attribute, but the value is binary. The value of race is White or Not_White.\n",
    "\n",
    "Fortunately, race has been one-hot-encoded so to replicate this we can just drop the features from the sensitive attribute that aren't `race_White`.\n",
    "\n",
    "The Dataset class is really just a guide that tells EthicML how to read the underlying CSV. So to remove the other race attributes, we can just not include them in our list of sensitive attribute columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Adult(\"Race\")\n",
    "dataset.sens_attrs = [\"race_White\"]\n",
    "data = load_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_White\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           0\n",
       "4           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ethicml.algorithms.inprocess import Agarwal, InAlgorithm, LR, SVM, Kamishima, Kamiran\n",
    "from ethicml.algorithms.preprocess import Upsampler\n",
    "from ethicml.metrics import Accuracy, CV, TPR, ProbPos\n",
    "from ethicml.evaluators import evaluate_models\n",
    "\n",
    "datasets = [dataset, Toy()]\n",
    "preprocess_models = [Upsampler()]\n",
    "# inprocess_models = [Agarwal(), Kamishima(), LR(), SVM(kernel='linear'), Kamiran()]\n",
    "inprocess_models = [LR(), SVM(kernel='linear'), Kamiran()]\n",
    "postprocess_models = []\n",
    "metrics = [Accuracy(), CV()]\n",
    "per_sens_metrics = [Accuracy(), TPR(), ProbPos()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:26<00:00,  3.33it/s, task=Kamiran & Calders LR, dataset=Toy, transform=Upsample, repeat=1]      \n"
     ]
    }
   ],
   "source": [
    "test123 = evaluate_models(datasets, preprocess_models, inprocess_models, postprocess_models, metrics, per_sens_metrics, test_mode=False, repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>CV</th>\n",
       "      <th>Accuracy_race_White_0</th>\n",
       "      <th>Accuracy_race_White_0-race_White_1</th>\n",
       "      <th>Accuracy_race_White_0/race_White_1</th>\n",
       "      <th>Accuracy_race_White_1</th>\n",
       "      <th>TPR_race_White_0</th>\n",
       "      <th>TPR_race_White_0-race_White_1</th>\n",
       "      <th>TPR_race_White_0/race_White_1</th>\n",
       "      <th>TPR_race_White_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Accuracy_s_0/s_1</th>\n",
       "      <th>Accuracy_s_1</th>\n",
       "      <th>TPR_s_0</th>\n",
       "      <th>TPR_s_0-s_1</th>\n",
       "      <th>TPR_s_0/s_1</th>\n",
       "      <th>TPR_s_1</th>\n",
       "      <th>prob_pos_s_0</th>\n",
       "      <th>prob_pos_s_0-s_1</th>\n",
       "      <th>prob_pos_s_0/s_1</th>\n",
       "      <th>prob_pos_s_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "      <th>repeat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"49\" valign=\"top\">Adult</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">no_transform</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.052664</td>\n",
       "      <td>0.941272</td>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.964297</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamishima</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.849420</td>\n",
       "      <td>0.905814</td>\n",
       "      <td>0.888006</td>\n",
       "      <td>0.044826</td>\n",
       "      <td>0.949520</td>\n",
       "      <td>0.843180</td>\n",
       "      <td>0.546729</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.875965</td>\n",
       "      <td>0.624145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850304</td>\n",
       "      <td>0.928949</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>0.943756</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.861913</td>\n",
       "      <td>0.938460</td>\n",
       "      <td>0.901509</td>\n",
       "      <td>0.045999</td>\n",
       "      <td>0.948975</td>\n",
       "      <td>0.855510</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.996967</td>\n",
       "      <td>0.586999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850525</td>\n",
       "      <td>0.926266</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.053692</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.843052</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.989743</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.918604</td>\n",
       "      <td>0.897538</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>0.940725</td>\n",
       "      <td>0.844336</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.974821</td>\n",
       "      <td>0.623167</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850415</td>\n",
       "      <td>0.928155</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.914970</td>\n",
       "      <td>0.898332</td>\n",
       "      <td>0.053868</td>\n",
       "      <td>0.940036</td>\n",
       "      <td>0.844464</td>\n",
       "      <td>0.593458</td>\n",
       "      <td>0.026288</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850636</td>\n",
       "      <td>0.930913</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>0.943205</td>\n",
       "      <td>0.843565</td>\n",
       "      <td>0.621495</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.986962</td>\n",
       "      <td>0.613392</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Upsample</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.799005</td>\n",
       "      <td>0.865892</td>\n",
       "      <td>0.854647</td>\n",
       "      <td>0.064639</td>\n",
       "      <td>0.924368</td>\n",
       "      <td>0.790008</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.789718</td>\n",
       "      <td>0.851146</td>\n",
       "      <td>0.849087</td>\n",
       "      <td>0.068968</td>\n",
       "      <td>0.918773</td>\n",
       "      <td>0.780118</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.026580</td>\n",
       "      <td>0.969854</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.793919</td>\n",
       "      <td>0.857253</td>\n",
       "      <td>0.849881</td>\n",
       "      <td>0.065011</td>\n",
       "      <td>0.923506</td>\n",
       "      <td>0.784870</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0.978284</td>\n",
       "      <td>0.883675</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.788834</td>\n",
       "      <td>0.851298</td>\n",
       "      <td>0.848292</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.918574</td>\n",
       "      <td>0.779219</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.026091</td>\n",
       "      <td>0.970392</td>\n",
       "      <td>0.881232</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"17\" valign=\"top\">no_transform</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.052664</td>\n",
       "      <td>0.941272</td>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.964297</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamishima</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.849420</td>\n",
       "      <td>0.905814</td>\n",
       "      <td>0.888006</td>\n",
       "      <td>0.044826</td>\n",
       "      <td>0.949520</td>\n",
       "      <td>0.843180</td>\n",
       "      <td>0.546729</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.875965</td>\n",
       "      <td>0.624145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850304</td>\n",
       "      <td>0.928949</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>0.943756</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.861913</td>\n",
       "      <td>0.938460</td>\n",
       "      <td>0.901509</td>\n",
       "      <td>0.045999</td>\n",
       "      <td>0.948975</td>\n",
       "      <td>0.855510</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.996967</td>\n",
       "      <td>0.586999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850525</td>\n",
       "      <td>0.926266</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.053692</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.843052</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.989743</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.918604</td>\n",
       "      <td>0.897538</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>0.940725</td>\n",
       "      <td>0.844336</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.974821</td>\n",
       "      <td>0.623167</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850415</td>\n",
       "      <td>0.928155</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.914970</td>\n",
       "      <td>0.898332</td>\n",
       "      <td>0.053868</td>\n",
       "      <td>0.940036</td>\n",
       "      <td>0.844464</td>\n",
       "      <td>0.593458</td>\n",
       "      <td>0.026288</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850636</td>\n",
       "      <td>0.930913</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>0.943205</td>\n",
       "      <td>0.843565</td>\n",
       "      <td>0.621495</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.986962</td>\n",
       "      <td>0.613392</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.052664</td>\n",
       "      <td>0.941272</td>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.964297</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamishima</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.849420</td>\n",
       "      <td>0.905814</td>\n",
       "      <td>0.888006</td>\n",
       "      <td>0.044826</td>\n",
       "      <td>0.949520</td>\n",
       "      <td>0.843180</td>\n",
       "      <td>0.546729</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.875965</td>\n",
       "      <td>0.624145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850304</td>\n",
       "      <td>0.928949</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>0.943756</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.861913</td>\n",
       "      <td>0.938460</td>\n",
       "      <td>0.901509</td>\n",
       "      <td>0.045999</td>\n",
       "      <td>0.948975</td>\n",
       "      <td>0.855510</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.996967</td>\n",
       "      <td>0.586999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850525</td>\n",
       "      <td>0.926266</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.053692</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.843052</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.989743</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.918604</td>\n",
       "      <td>0.897538</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>0.940725</td>\n",
       "      <td>0.844336</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.974821</td>\n",
       "      <td>0.623167</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850415</td>\n",
       "      <td>0.928155</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.914970</td>\n",
       "      <td>0.898332</td>\n",
       "      <td>0.053868</td>\n",
       "      <td>0.940036</td>\n",
       "      <td>0.844464</td>\n",
       "      <td>0.593458</td>\n",
       "      <td>0.026288</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Upsample</th>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.793919</td>\n",
       "      <td>0.857253</td>\n",
       "      <td>0.849881</td>\n",
       "      <td>0.065011</td>\n",
       "      <td>0.923506</td>\n",
       "      <td>0.784870</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0.978284</td>\n",
       "      <td>0.883675</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.788502</td>\n",
       "      <td>0.851169</td>\n",
       "      <td>0.848292</td>\n",
       "      <td>0.069458</td>\n",
       "      <td>0.918120</td>\n",
       "      <td>0.778834</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.025603</td>\n",
       "      <td>0.970931</td>\n",
       "      <td>0.880743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">no_transform</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.843007</td>\n",
       "      <td>0.928962</td>\n",
       "      <td>0.889251</td>\n",
       "      <td>0.053508</td>\n",
       "      <td>0.939828</td>\n",
       "      <td>0.835743</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>0.579074</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.841902</td>\n",
       "      <td>0.931427</td>\n",
       "      <td>0.884365</td>\n",
       "      <td>0.049134</td>\n",
       "      <td>0.944442</td>\n",
       "      <td>0.835231</td>\n",
       "      <td>0.553922</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.570395</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.843449</td>\n",
       "      <td>0.929112</td>\n",
       "      <td>0.888436</td>\n",
       "      <td>0.052054</td>\n",
       "      <td>0.941409</td>\n",
       "      <td>0.836382</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.976411</td>\n",
       "      <td>0.572324</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.844002</td>\n",
       "      <td>0.932603</td>\n",
       "      <td>0.887622</td>\n",
       "      <td>0.050472</td>\n",
       "      <td>0.943138</td>\n",
       "      <td>0.837150</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.581003</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850415</td>\n",
       "      <td>0.928155</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.914970</td>\n",
       "      <td>0.898332</td>\n",
       "      <td>0.053868</td>\n",
       "      <td>0.940036</td>\n",
       "      <td>0.844464</td>\n",
       "      <td>0.593458</td>\n",
       "      <td>0.026288</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>0.619746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.850415</td>\n",
       "      <td>0.930656</td>\n",
       "      <td>0.894361</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.843309</td>\n",
       "      <td>0.621495</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.986962</td>\n",
       "      <td>0.613392</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Upsample</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.788502</td>\n",
       "      <td>0.851169</td>\n",
       "      <td>0.848292</td>\n",
       "      <td>0.069458</td>\n",
       "      <td>0.918120</td>\n",
       "      <td>0.778834</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.025603</td>\n",
       "      <td>0.970931</td>\n",
       "      <td>0.880743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.793919</td>\n",
       "      <td>0.857253</td>\n",
       "      <td>0.849881</td>\n",
       "      <td>0.065011</td>\n",
       "      <td>0.923506</td>\n",
       "      <td>0.784870</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0.978284</td>\n",
       "      <td>0.883675</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-2410</th>\n",
       "      <td>0.789608</td>\n",
       "      <td>0.851017</td>\n",
       "      <td>0.849087</td>\n",
       "      <td>0.069097</td>\n",
       "      <td>0.918622</td>\n",
       "      <td>0.779990</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.026580</td>\n",
       "      <td>0.969854</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">no_transform</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.841902</td>\n",
       "      <td>0.931427</td>\n",
       "      <td>0.884365</td>\n",
       "      <td>0.049134</td>\n",
       "      <td>0.944442</td>\n",
       "      <td>0.835231</td>\n",
       "      <td>0.553922</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.570395</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.843449</td>\n",
       "      <td>0.929112</td>\n",
       "      <td>0.888436</td>\n",
       "      <td>0.052054</td>\n",
       "      <td>0.941409</td>\n",
       "      <td>0.836382</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.976411</td>\n",
       "      <td>0.572324</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.844002</td>\n",
       "      <td>0.932603</td>\n",
       "      <td>0.887622</td>\n",
       "      <td>0.050472</td>\n",
       "      <td>0.943138</td>\n",
       "      <td>0.837150</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.581003</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Upsample</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.752570</td>\n",
       "      <td>0.857605</td>\n",
       "      <td>0.819218</td>\n",
       "      <td>0.077118</td>\n",
       "      <td>0.905864</td>\n",
       "      <td>0.742101</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.831726</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.793035</td>\n",
       "      <td>0.863390</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>0.058564</td>\n",
       "      <td>0.930582</td>\n",
       "      <td>0.785084</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.980398</td>\n",
       "      <td>0.864995</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>1-4820</th>\n",
       "      <td>0.752570</td>\n",
       "      <td>0.857605</td>\n",
       "      <td>0.819218</td>\n",
       "      <td>0.077118</td>\n",
       "      <td>0.905864</td>\n",
       "      <td>0.742101</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.831726</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Toy</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">no_transform</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-7230</th>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.609302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993356</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.873950</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>0.390698</td>\n",
       "      <td>0.441424</td>\n",
       "      <td>0.699454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-7230</th>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.609302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993356</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.873950</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>0.390698</td>\n",
       "      <td>0.441424</td>\n",
       "      <td>0.699454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-7230</th>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.659666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.340334</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Upsample</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>0-7230</th>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.659666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.340334</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0-7230</th>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.659666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.340334</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>0-7230</th>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.659666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.340334</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">no_transform</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>1-9640</th>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.652586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880126</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.279012</td>\n",
       "      <td>0.701058</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.347414</td>\n",
       "      <td>0.473089</td>\n",
       "      <td>0.659341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>1-9640</th>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.650771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879587</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.270988</td>\n",
       "      <td>0.714750</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.349229</td>\n",
       "      <td>0.479019</td>\n",
       "      <td>0.670330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>1-9640</th>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.734147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909850</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.159259</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.265853</td>\n",
       "      <td>0.564096</td>\n",
       "      <td>0.609890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Upsample</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>1-9640</th>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.728652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915331</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.159259</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.271348</td>\n",
       "      <td>0.559060</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>1-9640</th>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.728652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915331</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.159259</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.271348</td>\n",
       "      <td>0.559060</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <th>1-9640</th>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.728652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915331</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.159259</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.271348</td>\n",
       "      <td>0.559060</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36824 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Accuracy        CV  \\\n",
       "dataset transform    model                repeat                       \n",
       "Adult   no_transform Agarwal LR           0-2410  0.851410  0.916525   \n",
       "                     Kamishima            0-2410  0.849420  0.905814   \n",
       "                     Logistic Regression  0-2410  0.850304  0.928949   \n",
       "                     SVM                  0-2410  0.861913  0.938460   \n",
       "                     Kamiran & Calders LR 0-2410  0.850525  0.926266   \n",
       "                     Agarwal LR           0-2410  0.851741  0.918604   \n",
       "                     Logistic Regression  0-2410  0.850415  0.928155   \n",
       "                     SVM                  0-2410  0.851962  0.914970   \n",
       "                     Kamiran & Calders LR 0-2410  0.850636  0.930913   \n",
       "        Upsample     Agarwal LR           0-2410  0.799005  0.865892   \n",
       "                     Logistic Regression  0-2410  0.789718  0.851146   \n",
       "                     SVM                  0-2410  0.793919  0.857253   \n",
       "                     Kamiran & Calders LR 0-2410  0.788834  0.851298   \n",
       "        no_transform Agarwal LR           0-2410  0.851410  0.916525   \n",
       "                     Kamishima            0-2410  0.849420  0.905814   \n",
       "                     Logistic Regression  0-2410  0.850304  0.928949   \n",
       "                     SVM                  0-2410  0.861913  0.938460   \n",
       "                     Kamiran & Calders LR 0-2410  0.850525  0.926266   \n",
       "                     Agarwal LR           0-2410  0.851741  0.918604   \n",
       "                     Logistic Regression  0-2410  0.850415  0.928155   \n",
       "                     SVM                  0-2410  0.851962  0.914970   \n",
       "                     Kamiran & Calders LR 0-2410  0.850636  0.930913   \n",
       "                     Agarwal LR           0-2410  0.851410  0.916525   \n",
       "                     Kamishima            0-2410  0.849420  0.905814   \n",
       "                     Logistic Regression  0-2410  0.850304  0.928949   \n",
       "                     SVM                  0-2410  0.861913  0.938460   \n",
       "                     Kamiran & Calders LR 0-2410  0.850525  0.926266   \n",
       "                     Agarwal LR           0-2410  0.851741  0.918604   \n",
       "                     Logistic Regression  0-2410  0.850415  0.928155   \n",
       "                     SVM                  0-2410  0.851962  0.914970   \n",
       "...                                                    ...       ...   \n",
       "        Upsample     SVM                  0-2410  0.793919  0.857253   \n",
       "                     Kamiran & Calders LR 0-2410  0.788502  0.851169   \n",
       "        no_transform Agarwal LR           1-4820  0.843007  0.928962   \n",
       "                     Logistic Regression  1-4820  0.841902  0.931427   \n",
       "                     SVM                  1-4820  0.843449  0.929112   \n",
       "                     Kamiran & Calders LR 1-4820  0.844002  0.932603   \n",
       "                     Logistic Regression  0-2410  0.850415  0.928155   \n",
       "                     SVM                  0-2410  0.851962  0.914970   \n",
       "                     Kamiran & Calders LR 0-2410  0.850415  0.930656   \n",
       "        Upsample     Logistic Regression  0-2410  0.788502  0.851169   \n",
       "                     SVM                  0-2410  0.793919  0.857253   \n",
       "                     Kamiran & Calders LR 0-2410  0.789608  0.851017   \n",
       "        no_transform Logistic Regression  1-4820  0.841902  0.931427   \n",
       "                     SVM                  1-4820  0.843449  0.929112   \n",
       "                     Kamiran & Calders LR 1-4820  0.844002  0.932603   \n",
       "        Upsample     Logistic Regression  1-4820  0.752570  0.857605   \n",
       "                     SVM                  1-4820  0.793035  0.863390   \n",
       "                     Kamiran & Calders LR 1-4820  0.752570  0.857605   \n",
       "Toy     no_transform Logistic Regression  0-7230  0.887500  0.609302   \n",
       "                     SVM                  0-7230  0.887500  0.609302   \n",
       "                     Kamiran & Calders LR 0-7230  0.877500  0.659666   \n",
       "        Upsample     Logistic Regression  0-7230  0.877500  0.659666   \n",
       "                     SVM                  0-7230  0.877500  0.659666   \n",
       "                     Kamiran & Calders LR 0-7230  0.877500  0.659666   \n",
       "        no_transform Logistic Regression  1-9640  0.852500  0.652586   \n",
       "                     SVM                  1-9640  0.862500  0.650771   \n",
       "                     Kamiran & Calders LR 1-9640  0.872500  0.734147   \n",
       "        Upsample     Logistic Regression  1-9640  0.870000  0.728652   \n",
       "                     SVM                  1-9640  0.870000  0.728652   \n",
       "                     Kamiran & Calders LR 1-9640  0.870000  0.728652   \n",
       "\n",
       "                                                  Accuracy_race_White_0  \\\n",
       "dataset transform    model                repeat                          \n",
       "Adult   no_transform Agarwal LR           0-2410               0.896743   \n",
       "                     Kamishima            0-2410               0.888006   \n",
       "                     Logistic Regression  0-2410               0.893566   \n",
       "                     SVM                  0-2410               0.901509   \n",
       "                     Kamiran & Calders LR 0-2410               0.896743   \n",
       "                     Agarwal LR           0-2410               0.897538   \n",
       "                     Logistic Regression  0-2410               0.894361   \n",
       "                     SVM                  0-2410               0.898332   \n",
       "                     Kamiran & Calders LR 0-2410               0.894361   \n",
       "        Upsample     Agarwal LR           0-2410               0.854647   \n",
       "                     Logistic Regression  0-2410               0.849087   \n",
       "                     SVM                  0-2410               0.849881   \n",
       "                     Kamiran & Calders LR 0-2410               0.848292   \n",
       "        no_transform Agarwal LR           0-2410               0.896743   \n",
       "                     Kamishima            0-2410               0.888006   \n",
       "                     Logistic Regression  0-2410               0.893566   \n",
       "                     SVM                  0-2410               0.901509   \n",
       "                     Kamiran & Calders LR 0-2410               0.896743   \n",
       "                     Agarwal LR           0-2410               0.897538   \n",
       "                     Logistic Regression  0-2410               0.894361   \n",
       "                     SVM                  0-2410               0.898332   \n",
       "                     Kamiran & Calders LR 0-2410               0.894361   \n",
       "                     Agarwal LR           0-2410               0.896743   \n",
       "                     Kamishima            0-2410               0.888006   \n",
       "                     Logistic Regression  0-2410               0.893566   \n",
       "                     SVM                  0-2410               0.901509   \n",
       "                     Kamiran & Calders LR 0-2410               0.896743   \n",
       "                     Agarwal LR           0-2410               0.897538   \n",
       "                     Logistic Regression  0-2410               0.894361   \n",
       "                     SVM                  0-2410               0.898332   \n",
       "...                                                                 ...   \n",
       "        Upsample     SVM                  0-2410               0.849881   \n",
       "                     Kamiran & Calders LR 0-2410               0.848292   \n",
       "        no_transform Agarwal LR           1-4820               0.889251   \n",
       "                     Logistic Regression  1-4820               0.884365   \n",
       "                     SVM                  1-4820               0.888436   \n",
       "                     Kamiran & Calders LR 1-4820               0.887622   \n",
       "                     Logistic Regression  0-2410               0.894361   \n",
       "                     SVM                  0-2410               0.898332   \n",
       "                     Kamiran & Calders LR 0-2410               0.894361   \n",
       "        Upsample     Logistic Regression  0-2410               0.848292   \n",
       "                     SVM                  0-2410               0.849881   \n",
       "                     Kamiran & Calders LR 0-2410               0.849087   \n",
       "        no_transform Logistic Regression  1-4820               0.884365   \n",
       "                     SVM                  1-4820               0.888436   \n",
       "                     Kamiran & Calders LR 1-4820               0.887622   \n",
       "        Upsample     Logistic Regression  1-4820               0.819218   \n",
       "                     SVM                  1-4820               0.843648   \n",
       "                     Kamiran & Calders LR 1-4820               0.819218   \n",
       "Toy     no_transform Logistic Regression  0-7230                    NaN   \n",
       "                     SVM                  0-7230                    NaN   \n",
       "                     Kamiran & Calders LR 0-7230                    NaN   \n",
       "        Upsample     Logistic Regression  0-7230                    NaN   \n",
       "                     SVM                  0-7230                    NaN   \n",
       "                     Kamiran & Calders LR 0-7230                    NaN   \n",
       "        no_transform Logistic Regression  1-9640                    NaN   \n",
       "                     SVM                  1-9640                    NaN   \n",
       "                     Kamiran & Calders LR 1-9640                    NaN   \n",
       "        Upsample     Logistic Regression  1-9640                    NaN   \n",
       "                     SVM                  1-9640                    NaN   \n",
       "                     Kamiran & Calders LR 1-9640                    NaN   \n",
       "\n",
       "                                                  Accuracy_race_White_0-race_White_1  \\\n",
       "dataset transform    model                repeat                                       \n",
       "Adult   no_transform Agarwal LR           0-2410                            0.052664   \n",
       "                     Kamishima            0-2410                            0.044826   \n",
       "                     Logistic Regression  0-2410                            0.050258   \n",
       "                     SVM                  0-2410                            0.045999   \n",
       "                     Kamiran & Calders LR 0-2410                            0.053692   \n",
       "                     Agarwal LR           0-2410                            0.053202   \n",
       "                     Logistic Regression  0-2410                            0.051052   \n",
       "                     SVM                  0-2410                            0.053868   \n",
       "                     Kamiran & Calders LR 0-2410                            0.050795   \n",
       "        Upsample     Agarwal LR           0-2410                            0.064639   \n",
       "                     Logistic Regression  0-2410                            0.068968   \n",
       "                     SVM                  0-2410                            0.065011   \n",
       "                     Kamiran & Calders LR 0-2410                            0.069073   \n",
       "        no_transform Agarwal LR           0-2410                            0.052664   \n",
       "                     Kamishima            0-2410                            0.044826   \n",
       "                     Logistic Regression  0-2410                            0.050258   \n",
       "                     SVM                  0-2410                            0.045999   \n",
       "                     Kamiran & Calders LR 0-2410                            0.053692   \n",
       "                     Agarwal LR           0-2410                            0.053202   \n",
       "                     Logistic Regression  0-2410                            0.051052   \n",
       "                     SVM                  0-2410                            0.053868   \n",
       "                     Kamiran & Calders LR 0-2410                            0.050795   \n",
       "                     Agarwal LR           0-2410                            0.052664   \n",
       "                     Kamishima            0-2410                            0.044826   \n",
       "                     Logistic Regression  0-2410                            0.050258   \n",
       "                     SVM                  0-2410                            0.045999   \n",
       "                     Kamiran & Calders LR 0-2410                            0.053692   \n",
       "                     Agarwal LR           0-2410                            0.053202   \n",
       "                     Logistic Regression  0-2410                            0.051052   \n",
       "                     SVM                  0-2410                            0.053868   \n",
       "...                                                                              ...   \n",
       "        Upsample     SVM                  0-2410                            0.065011   \n",
       "                     Kamiran & Calders LR 0-2410                            0.069458   \n",
       "        no_transform Agarwal LR           1-4820                            0.053508   \n",
       "                     Logistic Regression  1-4820                            0.049134   \n",
       "                     SVM                  1-4820                            0.052054   \n",
       "                     Kamiran & Calders LR 1-4820                            0.050472   \n",
       "                     Logistic Regression  0-2410                            0.051052   \n",
       "                     SVM                  0-2410                            0.053868   \n",
       "                     Kamiran & Calders LR 0-2410                            0.051052   \n",
       "        Upsample     Logistic Regression  0-2410                            0.069458   \n",
       "                     SVM                  0-2410                            0.065011   \n",
       "                     Kamiran & Calders LR 0-2410                            0.069097   \n",
       "        no_transform Logistic Regression  1-4820                            0.049134   \n",
       "                     SVM                  1-4820                            0.052054   \n",
       "                     Kamiran & Calders LR 1-4820                            0.050472   \n",
       "        Upsample     Logistic Regression  1-4820                            0.077118   \n",
       "                     SVM                  1-4820                            0.058564   \n",
       "                     Kamiran & Calders LR 1-4820                            0.077118   \n",
       "Toy     no_transform Logistic Regression  0-7230                                 NaN   \n",
       "                     SVM                  0-7230                                 NaN   \n",
       "                     Kamiran & Calders LR 0-7230                                 NaN   \n",
       "        Upsample     Logistic Regression  0-7230                                 NaN   \n",
       "                     SVM                  0-7230                                 NaN   \n",
       "                     Kamiran & Calders LR 0-7230                                 NaN   \n",
       "        no_transform Logistic Regression  1-9640                                 NaN   \n",
       "                     SVM                  1-9640                                 NaN   \n",
       "                     Kamiran & Calders LR 1-9640                                 NaN   \n",
       "        Upsample     Logistic Regression  1-9640                                 NaN   \n",
       "                     SVM                  1-9640                                 NaN   \n",
       "                     Kamiran & Calders LR 1-9640                                 NaN   \n",
       "\n",
       "                                                  Accuracy_race_White_0/race_White_1  \\\n",
       "dataset transform    model                repeat                                       \n",
       "Adult   no_transform Agarwal LR           0-2410                            0.941272   \n",
       "                     Kamishima            0-2410                            0.949520   \n",
       "                     Logistic Regression  0-2410                            0.943756   \n",
       "                     SVM                  0-2410                            0.948975   \n",
       "                     Kamiran & Calders LR 0-2410                            0.940126   \n",
       "                     Agarwal LR           0-2410                            0.940725   \n",
       "                     Logistic Regression  0-2410                            0.942918   \n",
       "                     SVM                  0-2410                            0.940036   \n",
       "                     Kamiran & Calders LR 0-2410                            0.943205   \n",
       "        Upsample     Agarwal LR           0-2410                            0.924368   \n",
       "                     Logistic Regression  0-2410                            0.918773   \n",
       "                     SVM                  0-2410                            0.923506   \n",
       "                     Kamiran & Calders LR 0-2410                            0.918574   \n",
       "        no_transform Agarwal LR           0-2410                            0.941272   \n",
       "                     Kamishima            0-2410                            0.949520   \n",
       "                     Logistic Regression  0-2410                            0.943756   \n",
       "                     SVM                  0-2410                            0.948975   \n",
       "                     Kamiran & Calders LR 0-2410                            0.940126   \n",
       "                     Agarwal LR           0-2410                            0.940725   \n",
       "                     Logistic Regression  0-2410                            0.942918   \n",
       "                     SVM                  0-2410                            0.940036   \n",
       "                     Kamiran & Calders LR 0-2410                            0.943205   \n",
       "                     Agarwal LR           0-2410                            0.941272   \n",
       "                     Kamishima            0-2410                            0.949520   \n",
       "                     Logistic Regression  0-2410                            0.943756   \n",
       "                     SVM                  0-2410                            0.948975   \n",
       "                     Kamiran & Calders LR 0-2410                            0.940126   \n",
       "                     Agarwal LR           0-2410                            0.940725   \n",
       "                     Logistic Regression  0-2410                            0.942918   \n",
       "                     SVM                  0-2410                            0.940036   \n",
       "...                                                                              ...   \n",
       "        Upsample     SVM                  0-2410                            0.923506   \n",
       "                     Kamiran & Calders LR 0-2410                            0.918120   \n",
       "        no_transform Agarwal LR           1-4820                            0.939828   \n",
       "                     Logistic Regression  1-4820                            0.944442   \n",
       "                     SVM                  1-4820                            0.941409   \n",
       "                     Kamiran & Calders LR 1-4820                            0.943138   \n",
       "                     Logistic Regression  0-2410                            0.942918   \n",
       "                     SVM                  0-2410                            0.940036   \n",
       "                     Kamiran & Calders LR 0-2410                            0.942918   \n",
       "        Upsample     Logistic Regression  0-2410                            0.918120   \n",
       "                     SVM                  0-2410                            0.923506   \n",
       "                     Kamiran & Calders LR 0-2410                            0.918622   \n",
       "        no_transform Logistic Regression  1-4820                            0.944442   \n",
       "                     SVM                  1-4820                            0.941409   \n",
       "                     Kamiran & Calders LR 1-4820                            0.943138   \n",
       "        Upsample     Logistic Regression  1-4820                            0.905864   \n",
       "                     SVM                  1-4820                            0.930582   \n",
       "                     Kamiran & Calders LR 1-4820                            0.905864   \n",
       "Toy     no_transform Logistic Regression  0-7230                                 NaN   \n",
       "                     SVM                  0-7230                                 NaN   \n",
       "                     Kamiran & Calders LR 0-7230                                 NaN   \n",
       "        Upsample     Logistic Regression  0-7230                                 NaN   \n",
       "                     SVM                  0-7230                                 NaN   \n",
       "                     Kamiran & Calders LR 0-7230                                 NaN   \n",
       "        no_transform Logistic Regression  1-9640                                 NaN   \n",
       "                     SVM                  1-9640                                 NaN   \n",
       "                     Kamiran & Calders LR 1-9640                                 NaN   \n",
       "        Upsample     Logistic Regression  1-9640                                 NaN   \n",
       "                     SVM                  1-9640                                 NaN   \n",
       "                     Kamiran & Calders LR 1-9640                                 NaN   \n",
       "\n",
       "                                                  Accuracy_race_White_1  \\\n",
       "dataset transform    model                repeat                          \n",
       "Adult   no_transform Agarwal LR           0-2410               0.844079   \n",
       "                     Kamishima            0-2410               0.843180   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.855510   \n",
       "                     Kamiran & Calders LR 0-2410               0.843052   \n",
       "                     Agarwal LR           0-2410               0.844336   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.844464   \n",
       "                     Kamiran & Calders LR 0-2410               0.843565   \n",
       "        Upsample     Agarwal LR           0-2410               0.790008   \n",
       "                     Logistic Regression  0-2410               0.780118   \n",
       "                     SVM                  0-2410               0.784870   \n",
       "                     Kamiran & Calders LR 0-2410               0.779219   \n",
       "        no_transform Agarwal LR           0-2410               0.844079   \n",
       "                     Kamishima            0-2410               0.843180   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.855510   \n",
       "                     Kamiran & Calders LR 0-2410               0.843052   \n",
       "                     Agarwal LR           0-2410               0.844336   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.844464   \n",
       "                     Kamiran & Calders LR 0-2410               0.843565   \n",
       "                     Agarwal LR           0-2410               0.844079   \n",
       "                     Kamishima            0-2410               0.843180   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.855510   \n",
       "                     Kamiran & Calders LR 0-2410               0.843052   \n",
       "                     Agarwal LR           0-2410               0.844336   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.844464   \n",
       "...                                                                 ...   \n",
       "        Upsample     SVM                  0-2410               0.784870   \n",
       "                     Kamiran & Calders LR 0-2410               0.778834   \n",
       "        no_transform Agarwal LR           1-4820               0.835743   \n",
       "                     Logistic Regression  1-4820               0.835231   \n",
       "                     SVM                  1-4820               0.836382   \n",
       "                     Kamiran & Calders LR 1-4820               0.837150   \n",
       "                     Logistic Regression  0-2410               0.843309   \n",
       "                     SVM                  0-2410               0.844464   \n",
       "                     Kamiran & Calders LR 0-2410               0.843309   \n",
       "        Upsample     Logistic Regression  0-2410               0.778834   \n",
       "                     SVM                  0-2410               0.784870   \n",
       "                     Kamiran & Calders LR 0-2410               0.779990   \n",
       "        no_transform Logistic Regression  1-4820               0.835231   \n",
       "                     SVM                  1-4820               0.836382   \n",
       "                     Kamiran & Calders LR 1-4820               0.837150   \n",
       "        Upsample     Logistic Regression  1-4820               0.742101   \n",
       "                     SVM                  1-4820               0.785084   \n",
       "                     Kamiran & Calders LR 1-4820               0.742101   \n",
       "Toy     no_transform Logistic Regression  0-7230                    NaN   \n",
       "                     SVM                  0-7230                    NaN   \n",
       "                     Kamiran & Calders LR 0-7230                    NaN   \n",
       "        Upsample     Logistic Regression  0-7230                    NaN   \n",
       "                     SVM                  0-7230                    NaN   \n",
       "                     Kamiran & Calders LR 0-7230                    NaN   \n",
       "        no_transform Logistic Regression  1-9640                    NaN   \n",
       "                     SVM                  1-9640                    NaN   \n",
       "                     Kamiran & Calders LR 1-9640                    NaN   \n",
       "        Upsample     Logistic Regression  1-9640                    NaN   \n",
       "                     SVM                  1-9640                    NaN   \n",
       "                     Kamiran & Calders LR 1-9640                    NaN   \n",
       "\n",
       "                                                  TPR_race_White_0  \\\n",
       "dataset transform    model                repeat                     \n",
       "Adult   no_transform Agarwal LR           0-2410          0.602804   \n",
       "                     Kamishima            0-2410          0.546729   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.588785   \n",
       "                     Kamiran & Calders LR 0-2410          0.626168   \n",
       "                     Agarwal LR           0-2410          0.607477   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.593458   \n",
       "                     Kamiran & Calders LR 0-2410          0.621495   \n",
       "        Upsample     Agarwal LR           0-2410          0.869159   \n",
       "                     Logistic Regression  0-2410          0.855140   \n",
       "                     SVM                  0-2410          0.864486   \n",
       "                     Kamiran & Calders LR 0-2410          0.855140   \n",
       "        no_transform Agarwal LR           0-2410          0.602804   \n",
       "                     Kamishima            0-2410          0.546729   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.588785   \n",
       "                     Kamiran & Calders LR 0-2410          0.626168   \n",
       "                     Agarwal LR           0-2410          0.607477   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.593458   \n",
       "                     Kamiran & Calders LR 0-2410          0.621495   \n",
       "                     Agarwal LR           0-2410          0.602804   \n",
       "                     Kamishima            0-2410          0.546729   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.588785   \n",
       "                     Kamiran & Calders LR 0-2410          0.626168   \n",
       "                     Agarwal LR           0-2410          0.607477   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.593458   \n",
       "...                                                            ...   \n",
       "        Upsample     SVM                  0-2410          0.864486   \n",
       "                     Kamiran & Calders LR 0-2410          0.855140   \n",
       "        no_transform Agarwal LR           1-4820          0.573529   \n",
       "                     Logistic Regression  1-4820          0.553922   \n",
       "                     SVM                  1-4820          0.558824   \n",
       "                     Kamiran & Calders LR 1-4820          0.578431   \n",
       "                     Logistic Regression  0-2410          0.602804   \n",
       "                     SVM                  0-2410          0.593458   \n",
       "                     Kamiran & Calders LR 0-2410          0.621495   \n",
       "        Upsample     Logistic Regression  0-2410          0.855140   \n",
       "                     SVM                  0-2410          0.864486   \n",
       "                     Kamiran & Calders LR 0-2410          0.855140   \n",
       "        no_transform Logistic Regression  1-4820          0.553922   \n",
       "                     SVM                  1-4820          0.558824   \n",
       "                     Kamiran & Calders LR 1-4820          0.578431   \n",
       "        Upsample     Logistic Regression  1-4820          0.833333   \n",
       "                     SVM                  1-4820          0.848039   \n",
       "                     Kamiran & Calders LR 1-4820          0.833333   \n",
       "Toy     no_transform Logistic Regression  0-7230               NaN   \n",
       "                     SVM                  0-7230               NaN   \n",
       "                     Kamiran & Calders LR 0-7230               NaN   \n",
       "        Upsample     Logistic Regression  0-7230               NaN   \n",
       "                     SVM                  0-7230               NaN   \n",
       "                     Kamiran & Calders LR 0-7230               NaN   \n",
       "        no_transform Logistic Regression  1-9640               NaN   \n",
       "                     SVM                  1-9640               NaN   \n",
       "                     Kamiran & Calders LR 1-9640               NaN   \n",
       "        Upsample     Logistic Regression  1-9640               NaN   \n",
       "                     SVM                  1-9640               NaN   \n",
       "                     Kamiran & Calders LR 1-9640               NaN   \n",
       "\n",
       "                                                  TPR_race_White_0-race_White_1  \\\n",
       "dataset transform    model                repeat                                  \n",
       "Adult   no_transform Agarwal LR           0-2410                       0.022318   \n",
       "                     Kamishima            0-2410                       0.077416   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.001786   \n",
       "                     Kamiran & Calders LR 0-2410                       0.006422   \n",
       "                     Agarwal LR           0-2410                       0.015691   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.026288   \n",
       "                     Kamiran & Calders LR 0-2410                       0.008103   \n",
       "        Upsample     Agarwal LR           0-2410                       0.001809   \n",
       "                     Logistic Regression  0-2410                       0.026580   \n",
       "                     SVM                  0-2410                       0.019189   \n",
       "                     Kamiran & Calders LR 0-2410                       0.026091   \n",
       "        no_transform Agarwal LR           0-2410                       0.022318   \n",
       "                     Kamishima            0-2410                       0.077416   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.001786   \n",
       "                     Kamiran & Calders LR 0-2410                       0.006422   \n",
       "                     Agarwal LR           0-2410                       0.015691   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.026288   \n",
       "                     Kamiran & Calders LR 0-2410                       0.008103   \n",
       "                     Agarwal LR           0-2410                       0.022318   \n",
       "                     Kamishima            0-2410                       0.077416   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.001786   \n",
       "                     Kamiran & Calders LR 0-2410                       0.006422   \n",
       "                     Agarwal LR           0-2410                       0.015691   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.026288   \n",
       "...                                                                         ...   \n",
       "        Upsample     SVM                  0-2410                       0.019189   \n",
       "                     Kamiran & Calders LR 0-2410                       0.025603   \n",
       "        no_transform Agarwal LR           1-4820                       0.005545   \n",
       "                     Logistic Regression  1-4820                       0.016474   \n",
       "                     SVM                  1-4820                       0.013500   \n",
       "                     Kamiran & Calders LR 1-4820                       0.002572   \n",
       "                     Logistic Regression  0-2410                       0.003257   \n",
       "                     SVM                  0-2410                       0.026288   \n",
       "                     Kamiran & Calders LR 0-2410                       0.008103   \n",
       "        Upsample     Logistic Regression  0-2410                       0.025603   \n",
       "                     SVM                  0-2410                       0.019189   \n",
       "                     Kamiran & Calders LR 0-2410                       0.026580   \n",
       "        no_transform Logistic Regression  1-4820                       0.016474   \n",
       "                     SVM                  1-4820                       0.013500   \n",
       "                     Kamiran & Calders LR 1-4820                       0.002572   \n",
       "        Upsample     Logistic Regression  1-4820                       0.001607   \n",
       "                     SVM                  1-4820                       0.016956   \n",
       "                     Kamiran & Calders LR 1-4820                       0.001607   \n",
       "Toy     no_transform Logistic Regression  0-7230                            NaN   \n",
       "                     SVM                  0-7230                            NaN   \n",
       "                     Kamiran & Calders LR 0-7230                            NaN   \n",
       "        Upsample     Logistic Regression  0-7230                            NaN   \n",
       "                     SVM                  0-7230                            NaN   \n",
       "                     Kamiran & Calders LR 0-7230                            NaN   \n",
       "        no_transform Logistic Regression  1-9640                            NaN   \n",
       "                     SVM                  1-9640                            NaN   \n",
       "                     Kamiran & Calders LR 1-9640                            NaN   \n",
       "        Upsample     Logistic Regression  1-9640                            NaN   \n",
       "                     SVM                  1-9640                            NaN   \n",
       "                     Kamiran & Calders LR 1-9640                            NaN   \n",
       "\n",
       "                                                  TPR_race_White_0/race_White_1  \\\n",
       "dataset transform    model                repeat                                  \n",
       "Adult   no_transform Agarwal LR           0-2410                       0.964297   \n",
       "                     Kamishima            0-2410                       0.875965   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.996967   \n",
       "                     Kamiran & Calders LR 0-2410                       0.989743   \n",
       "                     Agarwal LR           0-2410                       0.974821   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.957583   \n",
       "                     Kamiran & Calders LR 0-2410                       0.986962   \n",
       "        Upsample     Agarwal LR           0-2410                       0.997923   \n",
       "                     Logistic Regression  0-2410                       0.969854   \n",
       "                     SVM                  0-2410                       0.978284   \n",
       "                     Kamiran & Calders LR 0-2410                       0.970392   \n",
       "        no_transform Agarwal LR           0-2410                       0.964297   \n",
       "                     Kamishima            0-2410                       0.875965   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.996967   \n",
       "                     Kamiran & Calders LR 0-2410                       0.989743   \n",
       "                     Agarwal LR           0-2410                       0.974821   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.957583   \n",
       "                     Kamiran & Calders LR 0-2410                       0.986962   \n",
       "                     Agarwal LR           0-2410                       0.964297   \n",
       "                     Kamishima            0-2410                       0.875965   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.996967   \n",
       "                     Kamiran & Calders LR 0-2410                       0.989743   \n",
       "                     Agarwal LR           0-2410                       0.974821   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.957583   \n",
       "...                                                                         ...   \n",
       "        Upsample     SVM                  0-2410                       0.978284   \n",
       "                     Kamiran & Calders LR 0-2410                       0.970931   \n",
       "        no_transform Agarwal LR           1-4820                       0.990425   \n",
       "                     Logistic Regression  1-4820                       0.971119   \n",
       "                     SVM                  1-4820                       0.976411   \n",
       "                     Kamiran & Calders LR 1-4820                       0.995574   \n",
       "                     Logistic Regression  0-2410                       0.994626   \n",
       "                     SVM                  0-2410                       0.957583   \n",
       "                     Kamiran & Calders LR 0-2410                       0.986962   \n",
       "        Upsample     Logistic Regression  0-2410                       0.970931   \n",
       "                     SVM                  0-2410                       0.978284   \n",
       "                     Kamiran & Calders LR 0-2410                       0.969854   \n",
       "        no_transform Logistic Regression  1-4820                       0.971119   \n",
       "                     SVM                  1-4820                       0.976411   \n",
       "                     Kamiran & Calders LR 1-4820                       0.995574   \n",
       "        Upsample     Logistic Regression  1-4820                       0.998071   \n",
       "                     SVM                  1-4820                       0.980398   \n",
       "                     Kamiran & Calders LR 1-4820                       0.998071   \n",
       "Toy     no_transform Logistic Regression  0-7230                            NaN   \n",
       "                     SVM                  0-7230                            NaN   \n",
       "                     Kamiran & Calders LR 0-7230                            NaN   \n",
       "        Upsample     Logistic Regression  0-7230                            NaN   \n",
       "                     SVM                  0-7230                            NaN   \n",
       "                     Kamiran & Calders LR 0-7230                            NaN   \n",
       "        no_transform Logistic Regression  1-9640                            NaN   \n",
       "                     SVM                  1-9640                            NaN   \n",
       "                     Kamiran & Calders LR 1-9640                            NaN   \n",
       "        Upsample     Logistic Regression  1-9640                            NaN   \n",
       "                     SVM                  1-9640                            NaN   \n",
       "                     Kamiran & Calders LR 1-9640                            NaN   \n",
       "\n",
       "                                                  TPR_race_White_1  ...  \\\n",
       "dataset transform    model                repeat                    ...   \n",
       "Adult   no_transform Agarwal LR           0-2410          0.625122  ...   \n",
       "                     Kamishima            0-2410          0.624145  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.586999  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.619746  ...   \n",
       "                     Agarwal LR           0-2410          0.623167  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.619746  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.613392  ...   \n",
       "        Upsample     Agarwal LR           0-2410          0.870968  ...   \n",
       "                     Logistic Regression  0-2410          0.881720  ...   \n",
       "                     SVM                  0-2410          0.883675  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.881232  ...   \n",
       "        no_transform Agarwal LR           0-2410          0.625122  ...   \n",
       "                     Kamishima            0-2410          0.624145  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.586999  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.619746  ...   \n",
       "                     Agarwal LR           0-2410          0.623167  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.619746  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.613392  ...   \n",
       "                     Agarwal LR           0-2410          0.625122  ...   \n",
       "                     Kamishima            0-2410          0.624145  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.586999  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.619746  ...   \n",
       "                     Agarwal LR           0-2410          0.623167  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.619746  ...   \n",
       "...                                                            ...  ...   \n",
       "        Upsample     SVM                  0-2410          0.883675  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.880743  ...   \n",
       "        no_transform Agarwal LR           1-4820          0.579074  ...   \n",
       "                     Logistic Regression  1-4820          0.570395  ...   \n",
       "                     SVM                  1-4820          0.572324  ...   \n",
       "                     Kamiran & Calders LR 1-4820          0.581003  ...   \n",
       "                     Logistic Regression  0-2410          0.606061  ...   \n",
       "                     SVM                  0-2410          0.619746  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.613392  ...   \n",
       "        Upsample     Logistic Regression  0-2410          0.880743  ...   \n",
       "                     SVM                  0-2410          0.883675  ...   \n",
       "                     Kamiran & Calders LR 0-2410          0.881720  ...   \n",
       "        no_transform Logistic Regression  1-4820          0.570395  ...   \n",
       "                     SVM                  1-4820          0.572324  ...   \n",
       "                     Kamiran & Calders LR 1-4820          0.581003  ...   \n",
       "        Upsample     Logistic Regression  1-4820          0.831726  ...   \n",
       "                     SVM                  1-4820          0.864995  ...   \n",
       "                     Kamiran & Calders LR 1-4820          0.831726  ...   \n",
       "Toy     no_transform Logistic Regression  0-7230               NaN  ...   \n",
       "                     SVM                  0-7230               NaN  ...   \n",
       "                     Kamiran & Calders LR 0-7230               NaN  ...   \n",
       "        Upsample     Logistic Regression  0-7230               NaN  ...   \n",
       "                     SVM                  0-7230               NaN  ...   \n",
       "                     Kamiran & Calders LR 0-7230               NaN  ...   \n",
       "        no_transform Logistic Regression  1-9640               NaN  ...   \n",
       "                     SVM                  1-9640               NaN  ...   \n",
       "                     Kamiran & Calders LR 1-9640               NaN  ...   \n",
       "        Upsample     Logistic Regression  1-9640               NaN  ...   \n",
       "                     SVM                  1-9640               NaN  ...   \n",
       "                     Kamiran & Calders LR 1-9640               NaN  ...   \n",
       "\n",
       "                                                  Accuracy_s_0/s_1  \\\n",
       "dataset transform    model                repeat                     \n",
       "Adult   no_transform Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        Upsample     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "...                                                            ...   \n",
       "        Upsample     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Agarwal LR           1-4820               NaN   \n",
       "                     Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        Upsample     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "        Upsample     Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "Toy     no_transform Logistic Regression  0-7230          0.993356   \n",
       "                     SVM                  0-7230          0.993356   \n",
       "                     Kamiran & Calders LR 0-7230          0.983871   \n",
       "        Upsample     Logistic Regression  0-7230          0.983871   \n",
       "                     SVM                  0-7230          0.983871   \n",
       "                     Kamiran & Calders LR 0-7230          0.983871   \n",
       "        no_transform Logistic Regression  1-9640          0.880126   \n",
       "                     SVM                  1-9640          0.879587   \n",
       "                     Kamiran & Calders LR 1-9640          0.909850   \n",
       "        Upsample     Logistic Regression  1-9640          0.915331   \n",
       "                     SVM                  1-9640          0.915331   \n",
       "                     Kamiran & Calders LR 1-9640          0.915331   \n",
       "\n",
       "                                                  Accuracy_s_1   TPR_s_0  \\\n",
       "dataset transform    model                repeat                           \n",
       "Adult   no_transform Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Kamishima            0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "                     Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "        Upsample     Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "        no_transform Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Kamishima            0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "                     Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "                     Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Kamishima            0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "                     Agarwal LR           0-2410           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "...                                                        ...       ...   \n",
       "        Upsample     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "        no_transform Agarwal LR           1-4820           NaN       NaN   \n",
       "                     Logistic Regression  1-4820           NaN       NaN   \n",
       "                     SVM                  1-4820           NaN       NaN   \n",
       "                     Kamiran & Calders LR 1-4820           NaN       NaN   \n",
       "                     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "        Upsample     Logistic Regression  0-2410           NaN       NaN   \n",
       "                     SVM                  0-2410           NaN       NaN   \n",
       "                     Kamiran & Calders LR 0-2410           NaN       NaN   \n",
       "        no_transform Logistic Regression  1-4820           NaN       NaN   \n",
       "                     SVM                  1-4820           NaN       NaN   \n",
       "                     Kamiran & Calders LR 1-4820           NaN       NaN   \n",
       "        Upsample     Logistic Regression  1-4820           NaN       NaN   \n",
       "                     SVM                  1-4820           NaN       NaN   \n",
       "                     Kamiran & Calders LR 1-4820           NaN       NaN   \n",
       "Toy     no_transform Logistic Regression  0-7230      0.890710  0.800000   \n",
       "                     SVM                  0-7230      0.890710  0.800000   \n",
       "                     Kamiran & Calders LR 0-7230      0.885246  0.814286   \n",
       "        Upsample     Logistic Regression  0-7230      0.885246  0.814286   \n",
       "                     SVM                  0-7230      0.885246  0.814286   \n",
       "                     Kamiran & Calders LR 0-7230      0.885246  0.814286   \n",
       "        no_transform Logistic Regression  1-9640      0.912088  0.654321   \n",
       "                     SVM                  1-9640      0.923077  0.679012   \n",
       "                     Kamiran & Calders LR 1-9640      0.917582  0.740741   \n",
       "        Upsample     Logistic Regression  1-9640      0.912088  0.740741   \n",
       "                     SVM                  1-9640      0.912088  0.740741   \n",
       "                     Kamiran & Calders LR 1-9640      0.912088  0.740741   \n",
       "\n",
       "                                                  TPR_s_0-s_1  TPR_s_0/s_1  \\\n",
       "dataset transform    model                repeat                             \n",
       "Adult   no_transform Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Kamishima            0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "                     Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "        Upsample     Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "        no_transform Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Kamishima            0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "                     Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "                     Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Kamishima            0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "                     Agarwal LR           0-2410          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "...                                                       ...          ...   \n",
       "        Upsample     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "        no_transform Agarwal LR           1-4820          NaN          NaN   \n",
       "                     Logistic Regression  1-4820          NaN          NaN   \n",
       "                     SVM                  1-4820          NaN          NaN   \n",
       "                     Kamiran & Calders LR 1-4820          NaN          NaN   \n",
       "                     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "        Upsample     Logistic Regression  0-2410          NaN          NaN   \n",
       "                     SVM                  0-2410          NaN          NaN   \n",
       "                     Kamiran & Calders LR 0-2410          NaN          NaN   \n",
       "        no_transform Logistic Regression  1-4820          NaN          NaN   \n",
       "                     SVM                  1-4820          NaN          NaN   \n",
       "                     Kamiran & Calders LR 1-4820          NaN          NaN   \n",
       "        Upsample     Logistic Regression  1-4820          NaN          NaN   \n",
       "                     SVM                  1-4820          NaN          NaN   \n",
       "                     Kamiran & Calders LR 1-4820          NaN          NaN   \n",
       "Toy     no_transform Logistic Regression  0-7230     0.115385     0.873950   \n",
       "                     SVM                  0-7230     0.115385     0.873950   \n",
       "                     Kamiran & Calders LR 0-7230     0.078022     0.912562   \n",
       "        Upsample     Logistic Regression  0-7230     0.078022     0.912562   \n",
       "                     SVM                  0-7230     0.078022     0.912562   \n",
       "                     Kamiran & Calders LR 0-7230     0.078022     0.912562   \n",
       "        no_transform Logistic Regression  1-9640     0.279012     0.701058   \n",
       "                     SVM                  1-9640     0.270988     0.714750   \n",
       "                     Kamiran & Calders LR 1-9640     0.159259     0.823045   \n",
       "        Upsample     Logistic Regression  1-9640     0.159259     0.823045   \n",
       "                     SVM                  1-9640     0.159259     0.823045   \n",
       "                     Kamiran & Calders LR 1-9640     0.159259     0.823045   \n",
       "\n",
       "                                                   TPR_s_1  prob_pos_s_0  \\\n",
       "dataset transform    model                repeat                           \n",
       "Adult   no_transform Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Kamishima            0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "                     Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "        Upsample     Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "        no_transform Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Kamishima            0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "                     Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "                     Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Kamishima            0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "                     Agarwal LR           0-2410       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "...                                                    ...           ...   \n",
       "        Upsample     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "        no_transform Agarwal LR           1-4820       NaN           NaN   \n",
       "                     Logistic Regression  1-4820       NaN           NaN   \n",
       "                     SVM                  1-4820       NaN           NaN   \n",
       "                     Kamiran & Calders LR 1-4820       NaN           NaN   \n",
       "                     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "        Upsample     Logistic Regression  0-2410       NaN           NaN   \n",
       "                     SVM                  0-2410       NaN           NaN   \n",
       "                     Kamiran & Calders LR 0-2410       NaN           NaN   \n",
       "        no_transform Logistic Regression  1-4820       NaN           NaN   \n",
       "                     SVM                  1-4820       NaN           NaN   \n",
       "                     Kamiran & Calders LR 1-4820       NaN           NaN   \n",
       "        Upsample     Logistic Regression  1-4820       NaN           NaN   \n",
       "                     SVM                  1-4820       NaN           NaN   \n",
       "                     Kamiran & Calders LR 1-4820       NaN           NaN   \n",
       "Toy     no_transform Logistic Regression  0-7230  0.915385      0.308756   \n",
       "                     SVM                  0-7230  0.915385      0.308756   \n",
       "                     Kamiran & Calders LR 0-7230  0.892308      0.331797   \n",
       "        Upsample     Logistic Regression  0-7230  0.892308      0.331797   \n",
       "                     SVM                  0-7230  0.892308      0.331797   \n",
       "                     Kamiran & Calders LR 0-7230  0.892308      0.331797   \n",
       "        no_transform Logistic Regression  1-9640  0.933333      0.311927   \n",
       "                     SVM                  1-9640  0.950000      0.321101   \n",
       "                     Kamiran & Calders LR 1-9640  0.900000      0.344037   \n",
       "        Upsample     Logistic Regression  1-9640  0.900000      0.344037   \n",
       "                     SVM                  1-9640  0.900000      0.344037   \n",
       "                     Kamiran & Calders LR 1-9640  0.900000      0.344037   \n",
       "\n",
       "                                                  prob_pos_s_0-s_1  \\\n",
       "dataset transform    model                repeat                     \n",
       "Adult   no_transform Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        Upsample     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "...                                                            ...   \n",
       "        Upsample     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Agarwal LR           1-4820               NaN   \n",
       "                     Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        Upsample     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "        Upsample     Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "Toy     no_transform Logistic Regression  0-7230          0.390698   \n",
       "                     SVM                  0-7230          0.390698   \n",
       "                     Kamiran & Calders LR 0-7230          0.340334   \n",
       "        Upsample     Logistic Regression  0-7230          0.340334   \n",
       "                     SVM                  0-7230          0.340334   \n",
       "                     Kamiran & Calders LR 0-7230          0.340334   \n",
       "        no_transform Logistic Regression  1-9640          0.347414   \n",
       "                     SVM                  1-9640          0.349229   \n",
       "                     Kamiran & Calders LR 1-9640          0.265853   \n",
       "        Upsample     Logistic Regression  1-9640          0.271348   \n",
       "                     SVM                  1-9640          0.271348   \n",
       "                     Kamiran & Calders LR 1-9640          0.271348   \n",
       "\n",
       "                                                  prob_pos_s_0/s_1  \\\n",
       "dataset transform    model                repeat                     \n",
       "Adult   no_transform Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        Upsample     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Kamishima            0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "                     Agarwal LR           0-2410               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "...                                                            ...   \n",
       "        Upsample     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Agarwal LR           1-4820               NaN   \n",
       "                     Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "                     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        Upsample     Logistic Regression  0-2410               NaN   \n",
       "                     SVM                  0-2410               NaN   \n",
       "                     Kamiran & Calders LR 0-2410               NaN   \n",
       "        no_transform Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "        Upsample     Logistic Regression  1-4820               NaN   \n",
       "                     SVM                  1-4820               NaN   \n",
       "                     Kamiran & Calders LR 1-4820               NaN   \n",
       "Toy     no_transform Logistic Regression  0-7230          0.441424   \n",
       "                     SVM                  0-7230          0.441424   \n",
       "                     Kamiran & Calders LR 0-7230          0.493650   \n",
       "        Upsample     Logistic Regression  0-7230          0.493650   \n",
       "                     SVM                  0-7230          0.493650   \n",
       "                     Kamiran & Calders LR 0-7230          0.493650   \n",
       "        no_transform Logistic Regression  1-9640          0.473089   \n",
       "                     SVM                  1-9640          0.479019   \n",
       "                     Kamiran & Calders LR 1-9640          0.564096   \n",
       "        Upsample     Logistic Regression  1-9640          0.559060   \n",
       "                     SVM                  1-9640          0.559060   \n",
       "                     Kamiran & Calders LR 1-9640          0.559060   \n",
       "\n",
       "                                                  prob_pos_s_1  \n",
       "dataset transform    model                repeat                \n",
       "Adult   no_transform Agarwal LR           0-2410           NaN  \n",
       "                     Kamishima            0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "                     Agarwal LR           0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "        Upsample     Agarwal LR           0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "        no_transform Agarwal LR           0-2410           NaN  \n",
       "                     Kamishima            0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "                     Agarwal LR           0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "                     Agarwal LR           0-2410           NaN  \n",
       "                     Kamishima            0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "                     Agarwal LR           0-2410           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "...                                                        ...  \n",
       "        Upsample     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "        no_transform Agarwal LR           1-4820           NaN  \n",
       "                     Logistic Regression  1-4820           NaN  \n",
       "                     SVM                  1-4820           NaN  \n",
       "                     Kamiran & Calders LR 1-4820           NaN  \n",
       "                     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "        Upsample     Logistic Regression  0-2410           NaN  \n",
       "                     SVM                  0-2410           NaN  \n",
       "                     Kamiran & Calders LR 0-2410           NaN  \n",
       "        no_transform Logistic Regression  1-4820           NaN  \n",
       "                     SVM                  1-4820           NaN  \n",
       "                     Kamiran & Calders LR 1-4820           NaN  \n",
       "        Upsample     Logistic Regression  1-4820           NaN  \n",
       "                     SVM                  1-4820           NaN  \n",
       "                     Kamiran & Calders LR 1-4820           NaN  \n",
       "Toy     no_transform Logistic Regression  0-7230      0.699454  \n",
       "                     SVM                  0-7230      0.699454  \n",
       "                     Kamiran & Calders LR 0-7230      0.672131  \n",
       "        Upsample     Logistic Regression  0-7230      0.672131  \n",
       "                     SVM                  0-7230      0.672131  \n",
       "                     Kamiran & Calders LR 0-7230      0.672131  \n",
       "        no_transform Logistic Regression  1-9640      0.659341  \n",
       "                     SVM                  1-9640      0.670330  \n",
       "                     Kamiran & Calders LR 1-9640      0.609890  \n",
       "        Upsample     Logistic Regression  1-9640      0.615385  \n",
       "                     SVM                  1-9640      0.615385  \n",
       "                     Kamiran & Calders LR 1-9640      0.615385  \n",
       "\n",
       "[36824 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Accuracy_race_White_0/race_White_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TPR_race_White_0/race_White_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prob_pos_race_White_0/race_White_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">Adult</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Upsample</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <td>0.798355</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.928318</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.992380</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.671727</td>\n",
       "      <td>0.005150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <td>0.779580</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.915295</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.653193</td>\n",
       "      <td>0.010896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.780228</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.915456</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.977056</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.652570</td>\n",
       "      <td>0.011260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.793694</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.925306</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.659572</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">no_transform</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <td>0.850180</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.940825</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.974035</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.632836</td>\n",
       "      <td>0.011559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <td>0.849458</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.941908</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.672548</td>\n",
       "      <td>0.006965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamishima</th>\n",
       "      <td>0.849420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575863</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.849005</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.943269</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.989815</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>0.661139</td>\n",
       "      <td>0.007127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.943321</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.974201</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>0.639658</td>\n",
       "      <td>0.029777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Toy</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Upsample</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <td>0.849167</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <td>0.875893</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.875893</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.875893</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">no_transform</th>\n",
       "      <th>Agarwal LR</th>\n",
       "      <td>0.829219</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamiran &amp; Calders LR</th>\n",
       "      <td>0.876019</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.877130</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.880093</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Accuracy            \\\n",
       "                                               mean       std   \n",
       "dataset transform    model                                      \n",
       "Adult   Upsample     Agarwal LR            0.798355  0.001289   \n",
       "                     Kamiran & Calders LR  0.779580  0.015777   \n",
       "                     Logistic Regression   0.780228  0.016157   \n",
       "                     SVM                   0.793694  0.000385   \n",
       "        no_transform Agarwal LR            0.850180  0.003217   \n",
       "                     Kamiran & Calders LR  0.849458  0.002452   \n",
       "                     Kamishima             0.849420  0.000000   \n",
       "                     Logistic Regression   0.849005  0.003208   \n",
       "                     SVM                   0.853933  0.006490   \n",
       "Toy     Upsample     Agarwal LR            0.849167  0.011277   \n",
       "                     Kamiran & Calders LR  0.875893  0.003087   \n",
       "                     Logistic Regression   0.875893  0.003087   \n",
       "                     SVM                   0.875893  0.003087   \n",
       "        no_transform Agarwal LR            0.829219  0.032032   \n",
       "                     Kamiran & Calders LR  0.876019  0.002287   \n",
       "                     Logistic Regression   0.877130  0.016007   \n",
       "                     SVM                   0.880093  0.011433   \n",
       "\n",
       "                                          Accuracy_race_White_0/race_White_1  \\\n",
       "                                                                        mean   \n",
       "dataset transform    model                                                     \n",
       "Adult   Upsample     Agarwal LR                                     0.928318   \n",
       "                     Kamiran & Calders LR                           0.915295   \n",
       "                     Logistic Regression                            0.915456   \n",
       "                     SVM                                            0.925306   \n",
       "        no_transform Agarwal LR                                     0.940825   \n",
       "                     Kamiran & Calders LR                           0.941908   \n",
       "                     Kamishima                                      0.949520   \n",
       "                     Logistic Regression                            0.943269   \n",
       "                     SVM                                            0.943321   \n",
       "Toy     Upsample     Agarwal LR                                          NaN   \n",
       "                     Kamiran & Calders LR                                NaN   \n",
       "                     Logistic Regression                                 NaN   \n",
       "                     SVM                                                 NaN   \n",
       "        no_transform Agarwal LR                                          NaN   \n",
       "                     Kamiran & Calders LR                                NaN   \n",
       "                     Logistic Regression                                 NaN   \n",
       "                     SVM                                                 NaN   \n",
       "\n",
       "                                                     \\\n",
       "                                                std   \n",
       "dataset transform    model                            \n",
       "Adult   Upsample     Agarwal LR            0.006361   \n",
       "                     Kamiran & Calders LR  0.005510   \n",
       "                     Logistic Regression   0.005604   \n",
       "                     SVM                   0.003082   \n",
       "        no_transform Agarwal LR            0.000616   \n",
       "                     Kamiran & Calders LR  0.001486   \n",
       "                     Kamishima             0.000000   \n",
       "                     Logistic Regression   0.001007   \n",
       "                     SVM                   0.004103   \n",
       "Toy     Upsample     Agarwal LR                 NaN   \n",
       "                     Kamiran & Calders LR       NaN   \n",
       "                     Logistic Regression        NaN   \n",
       "                     SVM                        NaN   \n",
       "        no_transform Agarwal LR                 NaN   \n",
       "                     Kamiran & Calders LR       NaN   \n",
       "                     Logistic Regression        NaN   \n",
       "                     SVM                        NaN   \n",
       "\n",
       "                                          TPR_race_White_0/race_White_1  \\\n",
       "                                                                   mean   \n",
       "dataset transform    model                                                \n",
       "Adult   Upsample     Agarwal LR                                0.992380   \n",
       "                     Kamiran & Calders LR                      0.977441   \n",
       "                     Logistic Regression                       0.977056   \n",
       "                     SVM                                       0.978822   \n",
       "        no_transform Agarwal LR                                0.974035   \n",
       "                     Kamiran & Calders LR                      0.989484   \n",
       "                     Kamishima                                 0.875965   \n",
       "                     Logistic Regression                       0.989815   \n",
       "                     SVM                                       0.974201   \n",
       "Toy     Upsample     Agarwal LR                                     NaN   \n",
       "                     Kamiran & Calders LR                           NaN   \n",
       "                     Logistic Regression                            NaN   \n",
       "                     SVM                                            NaN   \n",
       "        no_transform Agarwal LR                                     NaN   \n",
       "                     Kamiran & Calders LR                           NaN   \n",
       "                     Logistic Regression                            NaN   \n",
       "                     SVM                                            NaN   \n",
       "\n",
       "                                                     \\\n",
       "                                                std   \n",
       "dataset transform    model                            \n",
       "Adult   Upsample     Agarwal LR            0.007494   \n",
       "                     Kamiran & Calders LR  0.012051   \n",
       "                     Logistic Regression   0.012277   \n",
       "                     SVM                   0.000920   \n",
       "        no_transform Agarwal LR            0.008606   \n",
       "                     Kamiran & Calders LR  0.003002   \n",
       "                     Kamishima             0.000000   \n",
       "                     Logistic Regression   0.008957   \n",
       "                     SVM                   0.017703   \n",
       "Toy     Upsample     Agarwal LR                 NaN   \n",
       "                     Kamiran & Calders LR       NaN   \n",
       "                     Logistic Regression        NaN   \n",
       "                     SVM                        NaN   \n",
       "        no_transform Agarwal LR                 NaN   \n",
       "                     Kamiran & Calders LR       NaN   \n",
       "                     Logistic Regression        NaN   \n",
       "                     SVM                        NaN   \n",
       "\n",
       "                                          prob_pos_race_White_0/race_White_1  \\\n",
       "                                                                        mean   \n",
       "dataset transform    model                                                     \n",
       "Adult   Upsample     Agarwal LR                                     0.671727   \n",
       "                     Kamiran & Calders LR                           0.653193   \n",
       "                     Logistic Regression                            0.652570   \n",
       "                     SVM                                            0.659572   \n",
       "        no_transform Agarwal LR                                     0.632836   \n",
       "                     Kamiran & Calders LR                           0.672548   \n",
       "                     Kamishima                                      0.575863   \n",
       "                     Logistic Regression                            0.661139   \n",
       "                     SVM                                            0.639658   \n",
       "Toy     Upsample     Agarwal LR                                          NaN   \n",
       "                     Kamiran & Calders LR                                NaN   \n",
       "                     Logistic Regression                                 NaN   \n",
       "                     SVM                                                 NaN   \n",
       "        no_transform Agarwal LR                                          NaN   \n",
       "                     Kamiran & Calders LR                                NaN   \n",
       "                     Logistic Regression                                 NaN   \n",
       "                     SVM                                                 NaN   \n",
       "\n",
       "                                                     \n",
       "                                                std  \n",
       "dataset transform    model                           \n",
       "Adult   Upsample     Agarwal LR            0.005150  \n",
       "                     Kamiran & Calders LR  0.010896  \n",
       "                     Logistic Regression   0.011260  \n",
       "                     SVM                   0.003557  \n",
       "        no_transform Agarwal LR            0.011559  \n",
       "                     Kamiran & Calders LR  0.006965  \n",
       "                     Kamishima             0.000000  \n",
       "                     Logistic Regression   0.007127  \n",
       "                     SVM                   0.029777  \n",
       "Toy     Upsample     Agarwal LR                 NaN  \n",
       "                     Kamiran & Calders LR       NaN  \n",
       "                     Logistic Regression        NaN  \n",
       "                     SVM                        NaN  \n",
       "        no_transform Agarwal LR                 NaN  \n",
       "                     Kamiran & Calders LR       NaN  \n",
       "                     Logistic Regression        NaN  \n",
       "                     SVM                        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test123.groupby(level=[0,1,2]).agg(['mean', 'std'])[['Accuracy', 'Accuracy_race_White_0/race_White_1', 'TPR_race_White_0/race_White_1', 'prob_pos_race_White_0/race_White_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 50/51 [41:59<00:50, 50.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from ethicml.algorithms.inprocess import Agarwal, InAlgorithm, LR, SVM, Kamishima\n",
    "from ethicml.algorithms.preprocess import Kamiran\n",
    "from ethicml.metrics import Accuracy, CV, TPR, ProbPos\n",
    "from ethicml.evaluators.evaluate_models import evaluate_models\n",
    "\n",
    "datasets = [Adult()]\n",
    "preprocess_models = []\n",
    "inprocess_models = [Agarwal(), Kamishima(), LR(), SVM()]\n",
    "postprocess_models = []\n",
    "metrics = [Accuracy(), CV()]\n",
    "per_sens_metrics = [Accuracy(), TPR(), ProbPos()]\n",
    "test123 = evaluate_models(datasets, preprocess_models, inprocess_models, postprocess_models, metrics, per_sens_metrics, test_mode=False, repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Accuracy_sex_Male_0/sex_Male_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TPR_sex_Male_0/sex_Male_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prob_pos_sex_Male_0/sex_Male_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Adult</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">no_transform</th>\n",
       "      <th>Agarwal</th>\n",
       "      <td>0.848572</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>1.139960</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.931315</td>\n",
       "      <td>0.086210</td>\n",
       "      <td>0.354343</td>\n",
       "      <td>0.040643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamishima</th>\n",
       "      <td>0.850384</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>1.137531</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.291610</td>\n",
       "      <td>0.013690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.850097</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>1.138135</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.297058</td>\n",
       "      <td>0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.864725</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>1.117742</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>0.757971</td>\n",
       "      <td>0.044756</td>\n",
       "      <td>0.260670</td>\n",
       "      <td>0.018487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Accuracy            \\\n",
       "                                              mean       std   \n",
       "dataset transform    model                                     \n",
       "Adult   no_transform Agarwal              0.848572  0.003176   \n",
       "                     Kamishima            0.850384  0.002961   \n",
       "                     Logistic Regression  0.850097  0.003253   \n",
       "                     SVM                  0.864725  0.002844   \n",
       "\n",
       "                                         Accuracy_sex_Male_0/sex_Male_1  \\\n",
       "                                                                   mean   \n",
       "dataset transform    model                                                \n",
       "Adult   no_transform Agarwal                                   1.139960   \n",
       "                     Kamishima                                 1.137531   \n",
       "                     Logistic Regression                       1.138135   \n",
       "                     SVM                                       1.117742   \n",
       "\n",
       "                                                   TPR_sex_Male_0/sex_Male_1  \\\n",
       "                                               std                      mean   \n",
       "dataset transform    model                                                     \n",
       "Adult   no_transform Agarwal              0.006937                  0.931315   \n",
       "                     Kamishima            0.007479                  0.815207   \n",
       "                     Logistic Regression  0.007381                  0.825997   \n",
       "                     SVM                  0.006871                  0.757971   \n",
       "\n",
       "                                                    \\\n",
       "                                               std   \n",
       "dataset transform    model                           \n",
       "Adult   no_transform Agarwal              0.086210   \n",
       "                     Kamishima            0.037357   \n",
       "                     Logistic Regression  0.034157   \n",
       "                     SVM                  0.044756   \n",
       "\n",
       "                                         prob_pos_sex_Male_0/sex_Male_1  \\\n",
       "                                                                   mean   \n",
       "dataset transform    model                                                \n",
       "Adult   no_transform Agarwal                                   0.354343   \n",
       "                     Kamishima                                 0.291610   \n",
       "                     Logistic Regression                       0.297058   \n",
       "                     SVM                                       0.260670   \n",
       "\n",
       "                                                    \n",
       "                                               std  \n",
       "dataset transform    model                          \n",
       "Adult   no_transform Agarwal              0.040643  \n",
       "                     Kamishima            0.013690  \n",
       "                     Logistic Regression  0.014001  \n",
       "                     SVM                  0.018487  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test123.groupby(level=[0,1,2]).agg(['mean', 'std'])[['Accuracy', 'Accuracy_sex_Male_0/sex_Male_1', 'TPR_sex_Male_0/sex_Male_1', 'prob_pos_sex_Male_0/sex_Male_1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
